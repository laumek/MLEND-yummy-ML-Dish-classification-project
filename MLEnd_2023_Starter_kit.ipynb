{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCzP3aRyELl7"
      },
      "source": [
        "# Enironment set up\n",
        "\n",
        "In this section we will set up a Colab environment for the MLEnd mini-project. Before starting, follow these simple instructions:\n",
        "\n",
        "1.   Go to https://drive.google.com/\n",
        "2.   Create a folder named 'Data' in 'MyDrive': On the left, click 'New' > 'Folder', enter the name **'Data'**, and click 'create'\n",
        "3.   Open the 'Data' folder and create a folder named **'MLEnd'**.\n",
        "\n",
        "Let's start by loading a few useful Python libraries and mounting our personal Google Drive storage system (i.e. making it available, so that Colab can access it)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzCE5tTM-x8L"
      },
      "outputs": [],
      "source": [
        "!pip install mlend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-X4yuoPk-6CC"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import spkit as sp\n",
        "\n",
        "from skimage import exposure\n",
        "from skimage.color import rgb2hsv, rgb2gray\n",
        "import skimage as ski\n",
        "\n",
        "import mlend\n",
        "from mlend import download_yummy_small, yummy_small_load\n",
        "\n",
        "import os, sys, re, pickle, glob\n",
        "import urllib.request\n",
        "import zipfile\n",
        "\n",
        "import IPython.display as ipd\n",
        "from tqdm import tqdm\n",
        "import librosa\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiWqi_RuEF4G"
      },
      "source": [
        "# Download data\n",
        "\n",
        "In this section we will download a small subsample of the MLEnd Yummy Dataset, i.e. the MLEnd Small Yummy Dataset. This dataset consists of a total of 99 samples from the MLEnd Yummy Dataset corresponding to dishes that contain either rice or chips.\n",
        "\n",
        "You should be able to download the entire training dataset using a similar approach to the one used here for the small sample. As you will see, you only need to provide a different link.\n",
        "\n",
        "Run the next code cell to download the MLEnd Small Yummy Dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-p_8myZeQdBs"
      },
      "outputs": [],
      "source": [
        "baseDir = download_yummy_small(save_to = '/content/drive/MyDrive/Data/MLEnd')\n",
        "baseDir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXUEPBnTa4QB"
      },
      "source": [
        "And now run the following cell to check the contents of the folder where you have downloaded your data into:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fB8XG2tjbNry"
      },
      "outputs": [],
      "source": [
        "os.listdir(baseDir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcPmd_5KbVAU"
      },
      "source": [
        "As you can see, there is a subfolder ('MLEndYD_images_small') together with a CSV file ('MLEndYD_image_attributes_small.csv'). The subfolder contains all the photos in the MLEnd Small Yummy dataset. You can also checking the contents of this folder via Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdDdp9rhRKC9"
      },
      "source": [
        "# Understanding our dataset\n",
        "\n",
        "Each sample in the MLEnd Small Yummy Dataset corresponds to one dish instance and is described by 9 attributes, namely:\n",
        "\n",
        "- Photo of the dish.\n",
        "- Dish name.\n",
        "- Whether home or restaurant.\n",
        "- Cuisine.\n",
        "- Ingredients.\n",
        "- Diet.\n",
        "- Healthiness rating.\n",
        "- Tastiness rating.\n",
        "- Rice or chips?\n",
        "\n",
        "As previously mentioned, only dishes containing either rice or chips have been included in the Small MLEnd Yummy Dataset. We captured this by adding the binary attribute *Rice or chips?*.\n",
        "\n",
        "We can imagine the MLEnd Small Yummy Dataset as a table that has 99 rows and 9 columns. Tables are a useful abstractions, but at the end of the day, we need to store the values of the attributes of each sample somewhere. Most of the attributes are text-based, and therefore can be stored using a text file, for instance, a CSV file. However, the photo attribute is a complex one that is not suitable to be stored in a text file. Consequently, we stored each photo in the separate folder *MLEndYD_images_small* as a JPEG file.\n",
        "\n",
        "The CSV file *MLEndYD_image_attributes_small.csv* captures the values of all the attributes of each sample. However, instead of an actual photo, this CSV file stores the name of the photo, e.g. '00001.jpg', that is stored in the separate folder *MLEndYD_images_small*.\n",
        "\n",
        "Let's look at the contents of this CSV file:\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tIeISIVjT-eN"
      },
      "outputs": [],
      "source": [
        "MLENDYD_df = pd.read_csv('/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_image_attributes_small.csv').set_index('filename')\n",
        "MLENDYD_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqVScjkDQid_"
      },
      "source": [
        "Note that there are 99 rows and 10 columns. The first column is used both as a unique indentifier (index) of the sample and also as a link to the photo of the dish. Pandas do not include the index column in the column count, and that's why it reports that the table has 9 columns.\n",
        "\n",
        "The 10th column ('Benchmark_A') is one that we have added for benchmarking purposes. This column indicates whether a sample should be used for training or for testing. Note that no sample is included in both training and test.\n",
        "\n",
        "If we now count the number of files in the *MLEndYD_images_small* folder, we obtain 99, as expected:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AjwbwA_xSJQO"
      },
      "outputs": [],
      "source": [
        "sample_path = '/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_images_small/*.jpg'\n",
        "files = glob.glob(sample_path)\n",
        "len(files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu_fGyfoSah2"
      },
      "source": [
        "Let's have a look at the first two photos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxGwx8eRSuUv"
      },
      "outputs": [],
      "source": [
        "I = plt.imread('/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_images_small/00001.jpg')\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(I)\n",
        "plt.axis('off')\n",
        "\n",
        "I = plt.imread('/content/drive/MyDrive/Data/MLEnd/yummy/MLEndYD_images_small/00002.jpg')\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(I)\n",
        "plt.axis('off')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfIQyoOLTec_"
      },
      "source": [
        "Both photos correspond to a dish that has chips. Note that their sizes are different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoHv54DNEVTF"
      },
      "source": [
        "# Create train and test Datasets\n",
        "\n",
        "In this Starter kit we will consider the problem of predicting whether a dish has rice or chips using a picture of the dish as the predictor.\n",
        "\n",
        "To solve this section, let us create two datasets, one for the training task and another one for the test task. We will use the `yummy_small_load` function included in our `mlend` library for this, and will specify which dataset each sample should belong to, by using the column 'Benchmark_A' in the CSV file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwYM2PDW_aFQ"
      },
      "outputs": [],
      "source": [
        "TrainSet, TestSet, Map = yummy_small_load(datadir_main=baseDir,train_test_split='Benchmark_A')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESmE73PKfask"
      },
      "source": [
        "`TrainSet` and `TrainSet` contain both datasets and `Map` describe how the values 'chips' and 'rice' are mapped to the values 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Iu8cewy_9Z0"
      },
      "outputs": [],
      "source": [
        "TrainSet.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78J99e4RAFdX"
      },
      "outputs": [],
      "source": [
        "TestSet.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1bOHw8YAMVc"
      },
      "outputs": [],
      "source": [
        "Map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XXPwXfPfwq1"
      },
      "source": [
        "Let us plot all the labels in the training dataset using the values 'chips' and 'rice':"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9FaQPCLAaCl"
      },
      "outputs": [],
      "source": [
        "TrainSet['Y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuY7C6jsf9pv"
      },
      "source": [
        "And now, let's plot the labels encoded using the values 0 and 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpfGYL1BCHA_"
      },
      "outputs": [],
      "source": [
        "TrainSet['Y_encoded']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F32WrmeHgOY6"
      },
      "source": [
        "Finally, let's save the predictors and labels of the training and test dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjisAHUtANcX"
      },
      "outputs": [],
      "source": [
        "X_train_paths = TrainSet['X_paths']\n",
        "X_test_paths  = TestSet['X_paths']\n",
        "\n",
        "Y_train = TrainSet['Y_encoded']\n",
        "Y_test  = TestSet['Y_encoded']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp2KRM_LEbnz"
      },
      "source": [
        "# Visualising dishes\n",
        "\n",
        "In this section, we will visualise the images that we have extracted from the MLEnd Small Yummy Dataset. Specifically, we will select five dishes that contain rice and five dishes that have chips?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "idhsjykqAhwK"
      },
      "outputs": [],
      "source": [
        "Chips_Img = np.array(X_train_paths)[Y_train==0]\n",
        "Rice_Img = np.array(X_train_paths)[Y_train==1]\n",
        "\n",
        "print('Rice')\n",
        "plt.figure(figsize=(15,5))\n",
        "for k,file in enumerate(Rice_Img[:5]):\n",
        "  I = plt.imread(file)\n",
        "  plt.subplot(1,5,k+1)\n",
        "  plt.imshow(I)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('Chips')\n",
        "plt.figure(figsize=(15,5))\n",
        "for k,file in enumerate(Chips_Img[:5]):\n",
        "  I = plt.imread(file)\n",
        "  plt.subplot(1,5,k+1)\n",
        "  plt.imshow(I)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ3Nw8kkF3cd"
      },
      "source": [
        "# Resizing Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTFfymp0FJs8"
      },
      "source": [
        "As previousle mentioned, images are not of same size. Our first step will be to resize all the images to so that they have the same size.\n",
        "\n",
        "To keep the aspect ratio of image as it is, we will append black color to make so that images are squared and then we will resize them to 200x200 pixels.\n",
        "\n",
        "You can choose any other size or approach to resize images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsS5cYAsKPsM"
      },
      "outputs": [],
      "source": [
        "def make_it_square(I, pad=0):\n",
        "  N,M,C = I.shape\n",
        "  if N>M:\n",
        "    Is = [np.pad(I[:,:,i], [(0,0),(0, N-M)], 'constant', constant_values=pad) for i in range(C)]\n",
        "  else:\n",
        "    Is = [np.pad(I[:,:,i], [(0, M-N),(0,0)], 'constant', constant_values=pad) for i in range(C)]\n",
        "\n",
        "  return np.array(Is).transpose([1,2,0])\n",
        "\n",
        "def resize_img(I,size=[100,100]):\n",
        "  N,M,C = I.shape\n",
        "  Ir = [sp.core.processing.resize(I[:,:,i],size) for i in range(C)]\n",
        "  return np.array(Ir).transpose([1,2,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYGLf4ImMqHx"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "for k,file in enumerate(X_train_paths):\n",
        "  sp.utils.ProgBar_JL(k,len(X_train_paths),L=50,color='blue')\n",
        "  I = plt.imread(file)\n",
        "  I = make_it_square(I, pad=0)\n",
        "  I = resize_img(I,size=[200,200])\n",
        "  X_train.append(I)\n",
        "\n",
        "\n",
        "X_test = []\n",
        "for k,file in enumerate(X_test_paths):\n",
        "  sp.utils.ProgBar_JL(k,len(X_test_paths),L=50,color='blue')\n",
        "  I = plt.imread(file)\n",
        "  I = make_it_square(I, pad=0)\n",
        "  I = resize_img(I,size=[200,200])\n",
        "  X_test.append(I)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Avz--hGGhOUM"
      },
      "source": [
        "Let's now plot a few images after resizing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTru3iWrbqap"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,6))\n",
        "for k,I in enumerate(X_train):\n",
        "  plt.subplot(3,5,k+1)\n",
        "  plt.imshow(I)\n",
        "  plt.axis('off')\n",
        "  k+=1\n",
        "  if k>=15:break\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Aw2j8VlizMV"
      },
      "source": [
        "As you can see, all the images have a square shape and consist of 200x200 pixels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvZOJJmCLhWX"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "To solve the problem of predicting whether a dish has rice or chips using a 200 x 200 pixels photo as the predictor, we need to start considering its dimensionality. Each photo is described by 3 x 200 x 200 = 120,000 values. Therefore, the predictor space has 120,000 dimensions. To train a model on such a space, we need a training dataset that has more than 120,000 samples. Needless to say, our training dataset is much, much smaller.\n",
        "\n",
        "Our only option is to reduce the dimensionality of the predictor space, in other words, we will move our samples from a 120,000D space to another space that has fewer dimensions. Feature extraction is a common approach that allows us to reduce the dimensionality of our prediction space. In the code cell below, we define two functions `get_yellow_component` and `GMLC_features` that extract three image features that will define a new predictor space:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YyuYJyaULh1T"
      },
      "outputs": [],
      "source": [
        "from skimage.feature import ORB\n",
        "from skimage.feature import graycomatrix, graycoprops\n",
        "\n",
        "\n",
        "def get_yellow_component(I,t1=27, t2=33):\n",
        "  Ihsv = (rgb2hsv(I)*255).astype('uint8')\n",
        "  mask = (Ihsv[:,:,0]<t2)*(Ihsv[:,:,0]>t1)\n",
        "  Ypx = mask.sum()\n",
        "  return Ypx\n",
        "\n",
        "def GMLC_features(I):\n",
        "  Ig = (rgb2gray(I)*255).astype('uint8')\n",
        "  glcm = graycomatrix(Ig, distances=[5], angles=[0], levels=256,\n",
        "                        symmetric=True, normed=True)\n",
        "  f1 = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
        "  f2 = graycoprops(glcm, 'correlation')[0, 0]\n",
        "  return f1,f2\n",
        "\n",
        "\n",
        "def showConfMat(CM, labels = ['Chips','Rice']):\n",
        "  plt.matshow(CM,cmap='Blues')\n",
        "  for i in range(CM.shape[0]):\n",
        "    for j in range(CM.shape[1]):\n",
        "      plt.text(i,j,CM[i,j].round(2),ha='center',)\n",
        "  plt.xticks([0,1],labels)\n",
        "  plt.yticks([0,1],labels)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxAqD6seljP7"
      },
      "source": [
        "Let us now extract the three features from each image and create the transform sets `X_train_f` and `X_test_f`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4A2RV27eR1yw"
      },
      "outputs": [],
      "source": [
        "X_train_f = []\n",
        "for k, I in enumerate(X_train):\n",
        "  f1 = get_yellow_component(I)\n",
        "  f2,f3 = GMLC_features(I)\n",
        "  X_train_f.append([f1,f2,f3])\n",
        "\n",
        "X_test_f = []\n",
        "for k, I in enumerate(X_test):\n",
        "  f1 = get_yellow_component(I)\n",
        "  f2,f3 = GMLC_features(I)\n",
        "  X_test_f.append([f1,f2,f3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6hcW_Nal8K9"
      },
      "source": [
        "After formatting both `X_train_f` and `X_test_f` as numpy arrays, we can check their respective shapes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYtq3rV5l8_W"
      },
      "outputs": [],
      "source": [
        "X_train_f = np.array(X_train_f)\n",
        "X_test_f = np.array(X_test_f)\n",
        "X_train_f.shape, X_test_f.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU5TOOB6mVF7"
      },
      "source": [
        "Note that `X_train_f` represents a collection of 70 samples described by 3 attributes and `X_test_f` represent a collection of 29 samples described by 3 attributes. This feature extraction stage has reduced the dimensionality of our problem from 120,000D to 3D."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1GRXiU9lYgdj"
      },
      "source": [
        "# Normalisation\n",
        "\n",
        "In addition to reducing the dimensionality of the prediction space, let's implement a normalisation stage to ensure that the 3 attributes in the new prediction space take on a similar range of values. We will implement standardisation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVwERsUuV9jb"
      },
      "outputs": [],
      "source": [
        "MEAN = X_train_f.mean(0)\n",
        "SD = X_train_f.std(0)\n",
        "\n",
        "X_train_fn = (X_train_f - MEAN)/SD\n",
        "X_test_fn = (X_test_f - MEAN)/SD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncj2OGlrYp8q"
      },
      "source": [
        "# Linear Model\n",
        "\n",
        "Finally, let's train and test a linear model that uses the 3 normalised attributes of an image to predict whether the image corresponds to a dish that has rice or chips.\n",
        "\n",
        "The linear model that we will use is called a 'Support Vector Machine'. It produces a linear boundary in the prediction space, but is trained using a different strategy that other linear models that we have seen in the class, such as logistic regression or discriminant analysis.\n",
        "\n",
        "Let us use the method LinearSVC available in scikit-learn to train a linear support vector machine:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtVQS_LWR11t"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "model = LinearSVC(C=1)\n",
        "model.fit(X_train_fn, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBPBRIp6oFac"
      },
      "source": [
        "Now, let's use this trained model to predict the labels in the training and test datasets and based on the predicted labels, let's calculate the training and test accuracy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPSSr2nOSO4G"
      },
      "outputs": [],
      "source": [
        "ytp = model.predict(X_train_fn)\n",
        "ysp = model.predict(X_test_fn)\n",
        "\n",
        "train_accuracy = np.mean(ytp==Y_train)\n",
        "test_accuracy  = np.mean(ysp==Y_test)\n",
        "\n",
        "print('Training Accuracy:\\t',train_accuracy)\n",
        "print('Test  Accuracy:\\t',test_accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8rKP0nTobTO"
      },
      "source": [
        "How well do you think the model is performing? Let's build a confusion matrix to look at the per-class accuracies:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zltLt7K8SO62"
      },
      "outputs": [],
      "source": [
        "Ac = np.mean(ysp[Y_test.astype(int)==0]==0)\n",
        "Ar = np.mean(ysp[Y_test.astype(int)==1]==1)\n",
        "\n",
        "Mc = np.mean(ysp[Y_test.astype(int)==0]==1)\n",
        "Mr = np.mean(ysp[Y_test.astype(int)==1]==0)\n",
        "\n",
        "CM = np.array([[Ac, Mc],[Mr, Ar]])\n",
        "\n",
        "showConfMat(CM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0DxFKlIoox7"
      },
      "source": [
        "What would you conclude from the per-class accuracies?\n",
        "\n",
        "One final question for you is, if we were to deploy this solution, what would be the *processing pipeline*? To answer this question, you need to identify all the steps that have taken us from a picture all the way to the prediction.\n",
        "\n",
        "You can try other machine learning models that use the same normalised predictors, or extract a different set of features. For instance, to train a Random Forest model simply run\n",
        "\n",
        "`model = RandomForestClassifier(n_estimators=5,max_depth=3)`\n",
        "\n",
        "It is surprisingly easy.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jz8Tq9Aez1a-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}